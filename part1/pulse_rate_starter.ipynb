{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.162557800694298"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "    Review the README in ./datasets/troika/ to understand the\n",
    "    organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that\n",
    "        ref_fls[5] is the reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "    Computes the MAE at 90% availability.\n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates\n",
    "        and corresponding reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates\n",
    "        for each pulse rate error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = np.abs(pr_errors[confidence_est >= percentile90_confidence])\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(best_estimates)\n",
    "\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and\n",
    "    returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs), errs, confs\n",
    "\n",
    "fs = 125\n",
    "window_len_s = 10\n",
    "window_shift_s = 2\n",
    "past_window = 3\n",
    "pass_band = (60/60.0, 200/60.0)\n",
    "multiplier = 4\n",
    "ppg_mag_height = 0.55\n",
    "acc_mag_height = 0.3\n",
    "ppg_min_dist = 0.2\n",
    "num_best = 2\n",
    "acc_num_best_arg = 2\n",
    "\n",
    "\n",
    "def BandpassFilter(signal):\n",
    "    \"\"\"\n",
    "    bandpass_filter\n",
    "    Loads the signal and passes it through a Butterworth filter.\n",
    "    Args:\n",
    "        signal: sinal Data from sensors\n",
    "    Returns:\n",
    "        Band Pass filtered Signal\n",
    "    \"\"\"\n",
    "    # Initialising Buterworth Bandpass Filter\n",
    "    b, a = scipy.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    '''Returns the signal after applying digital butterworth filter\n",
    "    forward and backward to a signal.'''\n",
    "    return scipy.signal.filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fft(sig, fs):\n",
    "    freqs = np.fft.rfftfreq(len(sig), 1/fs)\n",
    "    fft_mag = np.abs(np.fft.rfft(sig))\n",
    "    return (freqs, fft_mag)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file (signal).\n",
    "        ref_fl: (str) filepath to a troika .mat file (ground truth heart rate).\n",
    "\n",
    "    Returns:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and\n",
    "        corresponding reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse\n",
    "        rate error.\n",
    "    \"\"\"\n",
    "    fs = 125\n",
    "\n",
    "    # Load ground truth heart rate\n",
    "    ref_hrs = sp.io.loadmat(ref_fl)['BPM0']\n",
    "\n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    acc = np.mean([accx, accy, accz], axis=0)\n",
    "    data_list = [ppg, acc]\n",
    "    label_list = ['ppg', 'acc']\n",
    "\n",
    "    # Bandpass filter the signal between 70 and 190 BPM\n",
    "    filtered = {label: BandpassFilter(data) for (label, data) in zip(label_list, data_list)}\n",
    "\n",
    "    # Move with a window_length_s of 8s and the window_shift_s of 2s\n",
    "    # The ground truth data follows the same cadence\n",
    "    errors, confidence = [], []\n",
    "    window_length_s = 10\n",
    "    window_shift_s = 2\n",
    "    window_length = window_length_s * fs\n",
    "    window_shift = window_shift_s * fs\n",
    "    idx = list(range(0, len(ppg) - window_length, window_shift))\n",
    "    for i in idx:\n",
    "        segments = {label: filtered[label][\n",
    "            i: i + window_length] for label in label_list}\n",
    "\n",
    "        freqs, mags, sorted_inds, sorted_freqs = {}, {}, {}, {}\n",
    "        for label in label_list:\n",
    "            freqs[label], mags[label] = fft(segments[label], fs)\n",
    "            sorted_inds[label] = np.argsort(mags[label])[::-1][:4]\n",
    "            sorted_freqs[label] = freqs[label][sorted_inds[label]]\n",
    "\n",
    "        try:\n",
    "            est_f = [freq for freq in sorted_freqs['ppg']\n",
    "                     if freq not in sorted_freqs['acc']][0]\n",
    "\n",
    "        except:\n",
    "            ind = sorted_inds['ppg'][0]\n",
    "            est_f = freqs['ppg'][ind]\n",
    "\n",
    "        est_hr = est_f * 60\n",
    "        ref_hr = ref_hrs[idx.index(i)][0]\n",
    "        errors.append(np.mean(np.abs(est_hr-ref_hr)))\n",
    "        confidence.append(np.sum(mags['ppg'][(freqs['ppg'] >= est_f-30/60) & (\n",
    "                    freqs['ppg'] <= est_f+30/60)]) / np.sum(mags['ppg']))\n",
    "    return np.array(errors), np.array(confidence)\n",
    "\n",
    "metric, errs, confs = Evaluate()\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.66079295,  79.64253394,  78.85714286, ...,   1.3977    ,\n",
       "         0.25      ,   0.5596    ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.43493264,  0.34205628,  0.26265629, ...,  0.57230399,\n",
       "        0.54150599,  0.49534163])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** \n",
    ">   - The code estimates the pulse rate from the PPG signal and a 3-axis accelerometer. The pulse rate is restricted between 60BPM (beats per minute) and 200BPM. It produces an estimation confidence. A higher confidence value means that this estimate should be more accurate than an estimate with a lower confidence value. The code produces an output every 2 seconds.\n",
    "> - **Data Description** \n",
    "    - ECG signals have one channel.\n",
    "    - PPG signals have two channels. we take the second channel as it poses the more challenging problem and suggested. Here in the problem i have taken mean of both channels as it gives more accurate results.\n",
    "    - Accelerometers have three channels, each corresponding to a space axis x, y, and z. I use the magnitude of these three channels as distance calculation.   \n",
    "> - **Algorithhm Description** \n",
    ">   - RandomForestRegression on featurise data.\n",
    ">   - the specific aspects of the physiology that it takes advantage of : PPG signals can be used for measuring heart rate. Capillaries in the wrist fill with blood when the ventricles contract, when the blood passes light emitted by the PPG sensor is absorbed by red blood cells in these capillaries and the photodetector will see the cut in reflected light. Change in light measures and this oscillating waveform is the pulse rate.\n",
    ">   - a describtion of the algorithm outputs :\n",
    ">      - Outputs: the estimated frequency (in BPM) and the confidence score of that prediction.\n",
    ">   - caveats on algorithm outputs : The confidence rate is only calculated based on the magnitude of a small area that contains the estimated spectral frequency relative to the sum magnitude of the entire spectrum.\n",
    ">   - common failure modes : When the PPG picks a higher frequency signal that is not from the heart rate. This is possible due to hand movements, arm movement, alivation. To overcome with this, the accelerations measurmnet use in the algorithm.\n",
    "> - **Algorithm Performance** \n",
    ">   - Confidence estimates can be used to set the point on the error curve that I want to operate at by sacrificing the number of estimates that are considered valid. There is a trade-off between availability and error. For example if I want to operate at 90% availability, I look at the training dataset to determine the condince threshold for which 90% of the estimates pass. Then if only an estimate's confidence value is above that threshold do I consider it valid. The mean absolute error at 90% availability is 13.7 BPM on the test set. Put another way, the best 90% of the estimates--according to the confidence output-- has a mean absolute error of 13.7 BPM. Because the data were recorded on fixed actions, not in a free-living context. It may not generalize well on a free-living context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
